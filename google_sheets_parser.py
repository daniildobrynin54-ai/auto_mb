"""–ü–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –∏–∑ Google Sheets —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º —Å—Ç–æ–ª–±—Ü–∞."""

import re
import requests
from typing import Optional, Dict, Any
from bs4 import BeautifulSoup
from logger import get_logger

logger = get_logger("google_sheets")

# URL Google Sheets (–ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø)
SHEETS_URL = "https://docs.google.com/spreadsheets/d/1sYvrBU9BPhcoxTnNJfx8TOutxwFrSiRm2mw_8s6rdZM/gviz/tq?tqx=out:csv&gid=1142214254"


class GoogleSheetsParser:
    """–ü–∞—Ä—Å–µ—Ä –ø—Ä–æ—Ñ–∏–ª–µ–π –∏–∑ Google Sheets."""
    
    def __init__(self, proxy_manager=None):
        self.proxies = None
        if proxy_manager and proxy_manager.is_enabled():
            self.proxies = proxy_manager.get_proxies()
    
    def fetch_sheet_data(self) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets."""
        try:
            logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets...")
            
            response = requests.get(
                SHEETS_URL,
                proxies=self.proxies,
                timeout=15
            )
            
            if response.status_code == 200:
                logger.debug("‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                return response.text
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Sheets: {e}")
            return None
    
    def parse_profile(self, user_id: str) -> Optional[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è MangaBuff
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è –∏–ª–∏ None
        """
        csv_data = self.fetch_sheet_data()
        
        if not csv_data:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã")
            return None
        
        logger.debug(f"–ü–æ–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è user_id: {user_id}")
        
        # –ü–∞—Ä—Å–∏–º CSV
        lines = csv_data.strip().split('\n')
        
        if len(lines) < 2:
            logger.warning("–¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è")
            return None
        
        # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
        headers_line = lines[0]
        headers = [h.strip('"') for h in headers_line.split(',')]
        
        logger.debug(f"–ó–∞–≥–æ–ª–æ–≤–∫–∏: {headers}")
        
        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å—Ç–æ–ª–±—Ü–∞ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏
        link_column_index = None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
        possible_names = ['—Å—Å—ã–ª–∫–∞ –±–∞—Ñ—Ñ', '–ù–∏–∫', '–Ω–∏–∫ –±–∞—Ñ—Ñ', 'link', 'profile']
        for name in possible_names:
            try:
                link_column_index = headers.index(name)
                logger.info(f"–ù–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü '{name}' (–∏–Ω–¥–µ–∫—Å {link_column_index})")
                break
            except ValueError:
                continue
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é - –∏—â–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        if link_column_index is None:
            logger.info("–°—Ç–æ–ª–±–µ—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é, –∏—â–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É...")
            if len(lines) > 1:
                first_data_line = lines[1]
                values = self._parse_csv_line(first_data_line)
                
                for i, value in enumerate(values):
                    if 'HYPERLINK' in value and '/users/' in value:
                        link_column_index = i
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–∏–Ω–¥–µ–∫—Å {i})")
                        break
        
        if link_column_index is None:
            logger.error("‚ùå –°—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ")
            logger.error(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏: {headers}")
            return None
        
        # –ò—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å—Ç—Ä–æ–∫–∞—Ö
        for line in lines[1:]:
            # –†–∞–∑–¥–µ–ª—è–µ–º CSV —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫
            values = self._parse_csv_line(line)
            
            if len(values) <= link_column_index:
                continue
            
            # –í —Å—Ç–æ–ª–±—Ü–µ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ñ–æ—Ä–º—É–ª–∞ HYPERLINK:
            # =HYPERLINK("https://mangabuff.ru/users/258280";"LTM I PoliS")
            link_cell = values[link_column_index]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º user_id –∏–∑ HYPERLINK
            match = re.search(r'/users/(\d+)', link_cell)
            if not match:
                continue
            
            found_user_id = match.group(1)
            
            if found_user_id == user_id:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è {user_id}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ (–ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π –≤ HYPERLINK)
                name_match = re.search(r';"([^"]+)"', link_cell)
                username = name_match.group(1) if name_match else f"User{user_id}"
                
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø—Ä–æ—Ñ–∏–ª—è
                profile = {
                    'user_id': user_id,
                    'username': username
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                for i, header in enumerate(headers):
                    if i < len(values):
                        # –û—á–∏—â–∞–µ–º –æ—Ç HYPERLINK
                        value = self._clean_value(values[i])
                        profile[header] = value
                
                logger.debug(f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}")
                return profile
        
        logger.warning(f"–ü—Ä–æ—Ñ–∏–ª—å –¥–ª—è {user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ")
        return None
    
    def _parse_csv_line(self, line: str) -> list:
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É CSV —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫."""
        import csv
        import io
        
        reader = csv.reader(io.StringIO(line))
        return next(reader)
    
    def _clean_value(self, value: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç HYPERLINK –∏ –∫–∞–≤—ã—á–µ–∫."""
        # –£–±–∏—Ä–∞–µ–º HYPERLINK
        if 'HYPERLINK' in value:
            match = re.search(r';"([^"]+)"', value)
            if match:
                return match.group(1)
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏
        return value.strip('"')
    
    def format_profile_message(self, profile: Dict[str, Any]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –≤ –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram.
        
        Args:
            profile: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è
        
        Returns:
            HTML-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        username = profile.get('username', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        user_id = profile.get('user_id', '?')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        lines = [
            f"<b>üë§ –ü—Ä–æ—Ñ–∏–ª—å: {username}</b>",
            f"<code>ID: {user_id}</code>\n"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
        skip_fields = {
            'user_id', 
            'username', 
            '–ù–∏–∫', 
            '—Å—Å—ã–ª–∫–∞ –±–∞—Ñ—Ñ',  # üîß –î–û–ë–ê–í–õ–ï–ù–û: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å–æ —Å—Å—ã–ª–∫–∞–º–∏
            '–Ω–∏–∫ –±–∞—Ñ—Ñ'      # –≠—Ç–æ —É–∂–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–æ –∫–∞–∫ username
        }
        
        for key, value in profile.items():
            if key in skip_fields or not value:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—è –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if key.lower().startswith('id ') or key.lower() == 'id':
                continue
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è
            field_name = key.strip()
            field_value = str(value).strip()
            
            if field_value and field_value != '0':  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                lines.append(f"<b>{field_name}:</b> {field_value}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å
        lines.append(f"\nüîó <a href='https://mangabuff.ru/users/{user_id}'>–ü–µ—Ä–µ–π—Ç–∏ –≤ –ø—Ä–æ—Ñ–∏–ª—å</a>")
        
        return "\n".join(lines)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
_sheets_parser: Optional[GoogleSheetsParser] = None


def get_sheets_parser(proxy_manager=None) -> GoogleSheetsParser:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞."""
    global _sheets_parser
    
    if _sheets_parser is None:
        _sheets_parser = GoogleSheetsParser(proxy_manager)
    
    return _sheets_parser