"""–ü–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –∏–∑ Google Sheets."""

import re
import requests
from typing import Optional, Dict, Any
from bs4 import BeautifulSoup
from logger import get_logger

logger = get_logger("google_sheets")

# URL Google Sheets (–ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø)
SHEETS_URL = "https://docs.google.com/spreadsheets/d/1sYvrBU9BPhcoxTnNJfx8TOutxwFrSiRm2mw_8s6rdZM/gviz/tq?tqx=out:csv&gid=1142214254"


class GoogleSheetsParser:
    """–ü–∞—Ä—Å–µ—Ä –ø—Ä–æ—Ñ–∏–ª–µ–π –∏–∑ Google Sheets."""
    
    def __init__(self, proxy_manager=None):
        self.proxies = None
        if proxy_manager and proxy_manager.is_enabled():
            self.proxies = proxy_manager.get_proxies()
    
    def fetch_sheet_data(self) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets."""
        try:
            logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets...")
            
            response = requests.get(
                SHEETS_URL,
                proxies=self.proxies,
                timeout=15
            )
            
            if response.status_code == 200:
                logger.debug("‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                return response.text
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Sheets: {e}")
            return None
    
    def parse_profile(self, user_id: str) -> Optional[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è MangaBuff
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è –∏–ª–∏ None
        """
        csv_data = self.fetch_sheet_data()
        
        if not csv_data:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã")
            return None
        
        logger.debug(f"–ü–æ–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è user_id: {user_id}")
        
        # –ü–∞—Ä—Å–∏–º CSV
        lines = csv_data.strip().split('\n')
        
        if len(lines) < 2:
            logger.warning("–¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è")
            return None
        
        # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
        headers_line = lines[0]
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º
        headers = [h.strip('"') for h in headers_line.split(',')]
        
        logger.debug(f"–ó–∞–≥–æ–ª–æ–≤–∫–∏: {headers}")
        
        # –ò—â–µ–º –∏–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–±—Ü–∞ "–ù–∏–∫"
        try:
            name_index = headers.index('–ù–∏–∫')
        except ValueError:
            logger.error("–°—Ç–æ–ª–±–µ—Ü '–ù–∏–∫' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ")
            return None
        
        # –ò—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å—Ç—Ä–æ–∫–∞—Ö
        for line in lines[1:]:
            # –†–∞–∑–¥–µ–ª—è–µ–º CSV —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫
            values = self._parse_csv_line(line)
            
            if len(values) <= name_index:
                continue
            
            # –í —Å—Ç–æ–ª–±—Ü–µ "–ù–∏–∫" –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Å—ã–ª–∫–∞ —Ç–∏–ø–∞:
            # =HYPERLINK("https://mangabuff.ru/users/258280";"LTM I PoliS")
            name_cell = values[name_index]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º user_id –∏–∑ HYPERLINK
            match = re.search(r'/users/(\d+)', name_cell)
            if not match:
                continue
            
            found_user_id = match.group(1)
            
            if found_user_id == user_id:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è {user_id}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ (–ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π)
                name_match = re.search(r';"([^"]+)"', name_cell)
                username = name_match.group(1) if name_match else f"User{user_id}"
                
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø—Ä–æ—Ñ–∏–ª—è
                profile = {
                    'user_id': user_id,
                    'username': username
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                for i, header in enumerate(headers):
                    if i < len(values):
                        # –û—á–∏—â–∞–µ–º –æ—Ç HYPERLINK
                        value = self._clean_value(values[i])
                        profile[header] = value
                
                logger.debug(f"–ü—Ä–æ—Ñ–∏–ª—å: {profile}")
                return profile
        
        logger.warning(f"–ü—Ä–æ—Ñ–∏–ª—å –¥–ª—è {user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ")
        return None
    
    def _parse_csv_line(self, line: str) -> list:
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É CSV —Å —É—á–µ—Ç–æ–º –∫–∞–≤—ã—á–µ–∫."""
        import csv
        import io
        
        reader = csv.reader(io.StringIO(line))
        return next(reader)
    
    def _clean_value(self, value: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç HYPERLINK –∏ –∫–∞–≤—ã—á–µ–∫."""
        # –£–±–∏—Ä–∞–µ–º HYPERLINK
        if 'HYPERLINK' in value:
            match = re.search(r';"([^"]+)"', value)
            if match:
                return match.group(1)
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏
        return value.strip('"')
    
    def format_profile_message(self, profile: Dict[str, Any]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –≤ –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram.
        
        Args:
            profile: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è
        
        Returns:
            HTML-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        username = profile.get('username', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        user_id = profile.get('user_id', '?')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        lines = [
            f"<b>üë§ –ü—Ä–æ—Ñ–∏–ª—å: {username}</b>",
            f"<code>ID: {user_id}</code>\n"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
        skip_fields = {'user_id', 'username', '–ù–∏–∫'}
        
        for key, value in profile.items():
            if key in skip_fields or not value:
                continue
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è
            field_name = key.strip()
            field_value = str(value).strip()
            
            if field_value:
                lines.append(f"<b>{field_name}:</b> {field_value}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å
        lines.append(f"\nüîó <a href='https://mangabuff.ru/users/{user_id}'>–ü–µ—Ä–µ–π—Ç–∏ –≤ –ø—Ä–æ—Ñ–∏–ª—å</a>")
        
        return "\n".join(lines)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
_sheets_parser: Optional[GoogleSheetsParser] = None


def get_sheets_parser(proxy_manager=None) -> GoogleSheetsParser:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞."""
    global _sheets_parser
    
    if _sheets_parser is None:
        _sheets_parser = GoogleSheetsParser(proxy_manager)
    
    return _sheets_parser